<!DOCTYPE html>
<html lang="en">
<head>
  <link href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700&effect=destruction%7Cshadow-multiple" rel="stylesheet" type="text/css">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Parmap: Module parmap: efficient parallel map, fold and mapfold on lists and arrays on multicores.</title>
  <link href="/css/bootstrap.min.css" rel="stylesheet">
  <link href="/css/manpage.css" rel="stylesheet">
  <link rel="apple-touch-icon" sizes="57x57" href="/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192" href="/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png">
  <link rel="manifest" href="/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
  <meta name="description" content="Module parmap: efficient parallel map, fold and mapfold on lists and arrays on multicores.">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@CartaTech">
  <meta name="twitter:creator" content="@CartaTech">
  <meta name="twitter:title" content="Parmap (3) manual">
  <meta name="twitter:description" content="Module parmap: efficient parallel map, fold and mapfold on lists and arrays on multicores.">
  <meta name="twitter:image" content="https://www.carta.tech/images/libparmap-ocaml-dev-Parmap-3.png">
  <meta property="og:url" content="https://www.carta.tech/man-pages/man3/Parmap.3.html" />
  <meta property="og:type" content="website" />
  <meta property="og:title" content="Parmap (3) manual" />
  <meta property="og:description" content="Module parmap: efficient parallel map, fold and mapfold on lists and arrays on multicores." />
  <meta property="fb:app_id" content="1241677679199500" />
  <meta property="og:image" content="https://www.carta.tech/images/libparmap-ocaml-dev-Parmap-3.png" />
  <meta property="og:image:width" content="600" />
  <meta property="og:image:height" content="315" />
</head>
<body>
  <div class="container final">
          <div class="page-header">
        <h1 class="font-effect-destruction">Parmap<small> (3)</small></h1>
        <p class="lead">Module parmap: efficient parallel map, fold and mapfold on lists and arrays on multicores.</p>
      </div>

    <ol class="breadcrumb" itemscope itemtype="http://schema.org/BreadcrumbList">
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/">
      <span itemprop="name">Carta.tech</span>
    </a>
    <meta itemprop="position" content="1" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/">
      <span itemprop="name">Man Pages</span>
    </a>
    <meta itemprop="position" content="2" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/man3/">
      <span itemprop="name">Library calls</span>
    </a>
    <meta itemprop="position" content="3" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/man3/Parmap.3.html">
      <span itemprop="name">Parmap: Module parmap: efficient parallel map, fold and mapfold on lists and arrays on multicores.</span>
    </a>
    <meta itemprop="position" content="4" />
  </li>
</ol>
<ol class="breadcrumb" itemscope itemtype="http://schema.org/BreadcrumbList">
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/">
      <span itemprop="name">Carta.tech</span>
    </a>
    <meta itemprop="position" content="1" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/packages/">
      <span itemprop="name">Packages</span>
    </a>
    <meta itemprop="position" content="2" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/packages/libparmap-ocaml-dev/">
      <span itemprop="name">libparmap-ocaml-dev</span>
    </a>
    <meta itemprop="position" content="3" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/man3/Parmap.3.html">
      <span itemprop="name">Parmap: Module parmap: efficient parallel map, fold and mapfold on lists and arrays on multicores.</span>
    </a>
    <meta itemprop="position" content="4" />
  </li>
</ol>
    
      <section>
        <h2 class="font-effect-shadow-multiple">Module</h2>
        <div class="sectioncontent">
<p>Module   Parmap</p>
        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">Documentation</h2>
        <div class="sectioncontent">
<p>Module <strong>Parmap</strong>  : <strong>sig end</strong></p><p>Module <strong>Parmap</strong> : efficient parallel map, fold and mapfold on lists and arrays on multicores.</p><p>All the primitives allow to control the granularity of the parallelism via an optional parameter <strong>chunksize</strong> : if <strong>chunksize</strong> is omitted, the input sequence is split evenly among the available cores; if <strong>chunksize</strong> is specified, the input data is split in chunks of size <strong>chunksize</strong> and dispatched to the available cores using an on demand strategy that ensures automatic load balancing.</p><p>A specific primitive <strong>array_float_parmap</strong> is provided for fast operations on float arrays.</p><p><strong>===</strong> <strong>Setting and getting the default value for ncores</strong> <strong>===</strong></p><p><em>val set_default_ncores</em> : <strong>int -&gt; unit</strong></p><p><em>val get_default_ncores</em> : <strong>unit -&gt; int</strong></p><p><strong>===</strong> <strong>Sequence type, subsuming lists and arrays</strong> <strong>===</strong></p><p><em>type</em> <strong>'a</strong> <em>sequence</em> =  | L <strong>of</strong> <strong>'a list</strong>  | A <strong>of</strong> <strong>'a array</strong></p><p><strong>=== The parmapfold, parfold and parmap generic functions, for efficiency reasons,</strong> <strong>convert the input data into an array internally, so we provide the 'a sequence type</strong> <strong>to allow passing an array directly as input.</strong> <strong>If you want to perform a parallel map operation on an array, use array_parmap or array_float_parmap instead. ===</strong></p><p><strong>===</strong> <strong>Parallel mapfold</strong> <strong>===</strong></p><p><em>val parmapfold</em> : <strong>?init:(int -&gt; unit) -&gt;</strong> <strong>?finalize:(unit -&gt; unit) -&gt;</strong> <strong>?ncores:int -&gt;</strong> <strong>?chunksize:int -&gt;</strong> <strong>('a -&gt; 'b) -&gt;</strong> <strong>'a sequence -&gt; ('b -&gt; 'c -&gt; 'c) -&gt; 'c -&gt; ('c -&gt; 'c -&gt; 'c) -&gt; 'c</strong></p><p><strong>parmapfold ~ncores:n f (L l) op b concat</strong> computes <strong>List.fold_right op (List.map f l) b</strong> by forking <strong>n</strong> processes on a multicore machine. You need to provide the extra <strong>concat</strong> operator to combine the partial results of the fold computed on each core. If 'b = 'c, then <strong>concat</strong> may be simply <strong>op</strong> . The order of computation in parallel changes w.r.t. sequential execution, so this function is only correct if <strong>op</strong> and <strong>concat</strong> are associative and commutative. If the optional <strong>chunksize</strong> parameter is specified, the processes compute the result in an on-demand fashion on blocks of size <strong>chunksize</strong> . <strong>parmapfold ~ncores:n f (A a) op b concat</strong> computes <strong>Array.fold_right op (Array.map f a) b</strong></p><p><strong>===</strong> <strong>Parallel fold</strong> <strong>===</strong></p><p><em>val parfold</em> : <strong>?init:(int -&gt; unit) -&gt;</strong> <strong>?finalize:(unit -&gt; unit) -&gt;</strong> <strong>?ncores:int -&gt;</strong> <strong>?chunksize:int -&gt;</strong> <strong>('a -&gt; 'b -&gt; 'b) -&gt; 'a sequence -&gt; 'b -&gt; ('b -&gt; 'b -&gt; 'b) -&gt; 'b</strong></p><p><strong>parfold ~ncores:n op (L l) b concat</strong> computes <strong>List.fold_right op l b</strong> by forking <strong>n</strong> processes on a multicore machine. You need to provide the extra <strong>concat</strong> operator to combine the partial results of the fold computed on each core. If 'b = 'c, then <strong>concat</strong> may be simply <strong>op</strong> . The order of computation in parallel changes w.r.t. sequential execution, so this function is only correct if <strong>op</strong> and <strong>concat</strong> are associative and commutative. If the optional <strong>chunksize</strong> parameter is specified, the processes compute the result in an on-demand fashion on blocks of size <strong>chunksize</strong> . <strong>parfold ~ncores:n op (A a) b concat</strong> similarly computes <strong>Array.fold_right op a b</strong> .</p><p><strong>===</strong> <strong>Parallel map</strong> <strong>===</strong></p><p><em>val parmap</em> : <strong>?init:(int -&gt; unit) -&gt;</strong> <strong>?finalize:(unit -&gt; unit) -&gt;</strong> <strong>?ncores:int -&gt; ?chunksize:int -&gt; ('a -&gt; 'b) -&gt; 'a sequence -&gt; 'b list</strong></p><p><strong>parmap ~ncores:n f (L l)</strong> computes <strong>List.map f l</strong> by forking <strong>n</strong> processes on a multicore machine. <strong>parmap ~ncores:n f (A a)</strong> computes <strong>Array.map f a</strong> by forking <strong>n</strong> processes on a multicore machine. If the optional <strong>chunksize</strong> parameter is specified, the processes compute the result in an on-demand fashion on blocks of size <strong>chunksize</strong> ; this provides automatic load balancing for unbalanced computations, but the order of the result is no longer guaranteed to be preserved.</p><p><strong>===</strong> <strong>Parallel iteration</strong> <strong>===</strong></p><p><em>val pariter</em> : <strong>?init:(int -&gt; unit) -&gt;</strong> <strong>?finalize:(unit -&gt; unit) -&gt;</strong> <strong>?ncores:int -&gt; ?chunksize:int -&gt; ('a -&gt; unit) -&gt; 'a sequence -&gt; unit</strong></p><p><strong>pariter ~ncores:n f (L l)</strong> computes <strong>List.iter f l</strong> by forking <strong>n</strong> processes on a multicore machine. <strong>parmap ~ncores:n f (A a)</strong> computes <strong>Array.iter f a</strong> by forking <strong>n</strong> processes on a multicore machine. If the optional <strong>chunksize</strong> parameter is specified, the processes perform the computation in an on-demand fashion on blocks of size <strong>chunksize</strong> ; this provides automatic load balancing for unbalanced computations.</p><p><strong>===</strong> <strong>Parallel mapfold, indexed</strong> <strong>===</strong></p><p><em>val parmapifold</em> : <strong>?init:(int -&gt; unit) -&gt;</strong> <strong>?finalize:(unit -&gt; unit) -&gt;</strong> <strong>?ncores:int -&gt;</strong> <strong>?chunksize:int -&gt;</strong> <strong>(int -&gt; 'a -&gt; 'b) -&gt;</strong> <strong>'a sequence -&gt; ('b -&gt; 'c -&gt; 'c) -&gt; 'c -&gt; ('c -&gt; 'c -&gt; 'c) -&gt; 'c</strong></p><p>Like parmapfold, but the map function gets as an extra argument the index of the mapped element</p><p><strong>===</strong> <strong>Parallel map, indexed</strong> <strong>===</strong></p><p><em>val parmapi</em> : <strong>?init:(int -&gt; unit) -&gt;</strong> <strong>?finalize:(unit -&gt; unit) -&gt;</strong> <strong>?ncores:int -&gt;</strong> <strong>?chunksize:int -&gt; (int -&gt; 'a -&gt; 'b) -&gt; 'a sequence -&gt; 'b list</strong></p><p>Like parmap, but the map function gets as an extra argument the index of the mapped element</p><p><strong>===</strong> <strong>Parallel iteration, indexed</strong> <strong>===</strong></p><p><em>val pariteri</em> : <strong>?init:(int -&gt; unit) -&gt;</strong> <strong>?finalize:(unit -&gt; unit) -&gt;</strong> <strong>?ncores:int -&gt;</strong> <strong>?chunksize:int -&gt; (int -&gt; 'a -&gt; unit) -&gt; 'a sequence -&gt; unit</strong></p><p>Like pariter, but the iterated function gets as an extra argument the index of the sequence element</p><p><strong>===</strong> <strong>Parallel map on arrays</strong> <strong>===</strong></p><p><em>val array_parmap</em> : <strong>?init:(int -&gt; unit) -&gt;</strong> <strong>?finalize:(unit -&gt; unit) -&gt;</strong> <strong>?ncores:int -&gt; ?chunksize:int -&gt; ('a -&gt; 'b) -&gt; 'a array -&gt; 'b array</strong></p><p><strong>array_parmap ~ncores:n f a</strong> computes <strong>Array.map f a</strong> by forking <strong>n</strong> processes on a multicore machine. If the optional <strong>chunksize</strong> parameter is specified, the processes compute the result in an on-demand fashion on blochs of size <strong>chunksize</strong> ; this provides automatic load balancing for unbalanced computations, but the order of the result is no longer guaranteed to be preserved.</p><p><strong>===</strong> <strong>Parallel map on arrays, indexed</strong> <strong>===</strong></p><p><em>val array_parmapi</em> : <strong>?init:(int -&gt; unit) -&gt;</strong> <strong>?finalize:(unit -&gt; unit) -&gt;</strong> <strong>?ncores:int -&gt; ?chunksize:int -&gt; (int -&gt; 'a -&gt; 'b) -&gt; 'a array -&gt; 'b array</strong></p><p>Like array_parmap, but the map function gets as an extra argument the index of the mapped element</p><p><strong>===</strong> <strong>Parallel map on float arrays</strong> <strong>===</strong></p><p><em>exception WrongArraySize</em></p><p><em>type buf</em></p><p><em>val init_shared_buffer</em> : <strong>float array -&gt; buf</strong></p><p><strong>init_shared_buffer a</strong> creates a new memory mapped shared buffer big enough to hold a float array of the size of <strong>a</strong> . This buffer can be reused in a series of calls to <strong>array_float_parmap</strong> , avoiding the cost of reallocating it each time.</p><p><em>val array_float_parmap</em> : <strong>?init:(int -&gt; unit) -&gt;</strong> <strong>?finalize:(unit -&gt; unit) -&gt;</strong> <strong>?ncores:int -&gt;</strong> <strong>?chunksize:int -&gt;</strong> <strong>?result:float array -&gt;</strong> <strong>?sharedbuffer:buf -&gt; ('a -&gt; float) -&gt; 'a array -&gt; float array</strong></p><p><strong>array_float_parmap ~ncores:n f a</strong> computes <strong>Array.map f a</strong> by forking <strong>n</strong> processes on a multicore machine, and preallocating the resulting array as shared memory, which allows significantly more efficient computation than calling the generic array_parmap function.  If the optional <strong>chunksize</strong> parameter is specified, the processes compute the result in an on-demand fashion on blochs of size <strong>chunksize</strong> ; this provides automatic load balancing for unbalanced computations, *and* the order of the result is still guaranteed to be preserved.</p><p>In case you already have at hand an array where to store the result, you can squeeze out some more cpu cycles by passing it as optional parameter <strong>result</strong> : this will avoid the creation of a result array, which can be costly for very large data sets. Raises <strong>WrongArraySize</strong> if <strong>result</strong> is too small to hold the data.</p><p>It is possible to share the same preallocated shared memory space across calls, by initialising the space calling <strong>init_shared_buffer a</strong> and passing the result as the optional <strong>sharedbuffer</strong> parameter to each subsequent call to <strong>array_float_parmap</strong> .  Raises WrongArraySize if <strong>sharedbuffer</strong> is too small to hold the input data.</p><p><strong>===</strong> <strong>Parallel map on float arrays, indexed</strong> <strong>===</strong></p><p><em>val array_float_parmapi</em> : <strong>?init:(int -&gt; unit) -&gt;</strong> <strong>?finalize:(unit -&gt; unit) -&gt;</strong> <strong>?ncores:int -&gt;</strong> <strong>?chunksize:int -&gt;</strong> <strong>?result:float array -&gt;</strong> <strong>?sharedbuffer:buf -&gt; (int -&gt; 'a -&gt; float) -&gt; 'a array -&gt; float array</strong></p><p><strong>=== Like array_float_parmap, but the map function gets as an extra argument</strong> <strong>the index of the mapped element ===</strong></p><p><strong>===</strong> <strong>Debugging</strong> <strong>===</strong></p><p><em>val debugging</em> : <strong>bool -&gt; unit</strong></p><p><strong>=== Enable or disable debugging code in the library; default: false ===</strong></p><p><strong>===</strong> <strong>Helper function for redirection of stdout and stderr</strong> <strong>===</strong></p><p><em>val redirect</em> : <strong>?path:string -&gt; id:int -&gt; unit</strong></p><p><strong>=== Helper function that redirects stdout and stderr to files</strong> <strong>located in the directory path, carrying names of the shape</strong> <strong>stdout.NNN and stderr.NNN where NNN is the id of the used core.</strong> <strong>Useful when writing initialisation functions to be passed as</strong> <strong>init argument to the parallel combinators.</strong> <strong>The default value for path is /tmp/.parmap.PPPP with PPPP the</strong> <strong>process id of the main program. ===</strong></p>
        </div>
      </section>
<nav>
  <ul class="pager">
   <li class="previous"><a href="PX_write_primary_index.3.html"><span aria-hidden="true">&larr;</span> PX_write_primary_index.3: Px_write_primary_index  write primary index into a file</a></li>
   <li class="next"><a href="Participant.3.html">Participant.3: A class of objects representing remote participants (rtp applications) in a multimedia session. <span aria-hidden="true">&rarr;</span></a></li>
  </ul>
</nav>

  </div>
  <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
  <!-- Include all compiled plugins (below), or include individual files as needed -->
  <script src="/js/bootstrap.min.js"></script>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-60781387-1', 'auto');
    ga('send', 'pageview');

  </script>
</body>
</html>
