<!DOCTYPE html>
<html lang="en">
<head>
  <link href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700&effect=destruction%7Cshadow-multiple" rel="stylesheet" type="text/css">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>dupemap: Creates a database of file checksums and uses it to eliminate duplicates</title>
  <link href="/css/bootstrap.min.css" rel="stylesheet">
  <link href="/css/manpage.css" rel="stylesheet">
  <link rel="apple-touch-icon" sizes="57x57" href="/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192" href="/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png">
  <link rel="manifest" href="/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
  <meta name="description" content="Creates a database of file checksums and uses it to eliminate duplicates">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@CartaTech">
  <meta name="twitter:creator" content="@CartaTech">
  <meta name="twitter:title" content="dupemap (1) manual">
  <meta name="twitter:description" content="Creates a database of file checksums and uses it to eliminate duplicates">
  <meta name="twitter:image" content="https://www.carta.tech/images/magicrescue-dupemap-1.png">
  <meta property="og:url" content="https://www.carta.tech/man-pages/man1/dupemap.1.html" />
  <meta property="og:type" content="website" />
  <meta property="og:title" content="dupemap (1) manual" />
  <meta property="og:description" content="Creates a database of file checksums and uses it to eliminate duplicates" />
  <meta property="fb:app_id" content="1241677679199500" />
  <meta property="og:image" content="https://www.carta.tech/images/magicrescue-dupemap-1.png" />
  <meta property="og:image:width" content="600" />
  <meta property="og:image:height" content="315" />
</head>
<body>
  <div class="container final">
          <div class="page-header">
        <h1 class="font-effect-destruction">dupemap<small> (1)</small></h1>
        <p class="lead">Creates a database of file checksums and uses it to eliminate duplicates</p>
      </div>

    <ol class="breadcrumb" itemscope itemtype="http://schema.org/BreadcrumbList">
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/">
      <span itemprop="name">Carta.tech</span>
    </a>
    <meta itemprop="position" content="1" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/">
      <span itemprop="name">Man Pages</span>
    </a>
    <meta itemprop="position" content="2" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/man1/">
      <span itemprop="name">Executable programs or shell commands</span>
    </a>
    <meta itemprop="position" content="3" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/man1/dupemap.1.html">
      <span itemprop="name">dupemap: Creates a database of file checksums and uses it to eliminate duplicates</span>
    </a>
    <meta itemprop="position" content="4" />
  </li>
</ol>
<ol class="breadcrumb" itemscope itemtype="http://schema.org/BreadcrumbList">
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/">
      <span itemprop="name">Carta.tech</span>
    </a>
    <meta itemprop="position" content="1" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/packages/">
      <span itemprop="name">Packages</span>
    </a>
    <meta itemprop="position" content="2" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/packages/magicrescue/">
      <span itemprop="name">magicrescue</span>
    </a>
    <meta itemprop="position" content="3" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/man1/dupemap.1.html">
      <span itemprop="name">dupemap: Creates a database of file checksums and uses it to eliminate duplicates</span>
    </a>
    <meta itemprop="position" content="4" />
  </li>
</ol>
    
      <section>
        <h2 class="font-effect-shadow-multiple">SYNOPSIS</h2>
        <div class="sectioncontent">
<p><strong>dupemap</strong> [ <em>options</em> ] [ <strong>-d</strong> <em>database</em> ] <em>operation</em> <em>path...</em></p>
        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">DESCRIPTION</h2>
        <div class="sectioncontent">
<p><strong>dupemap</strong> recursively scans each <em>path</em> to find checksums of file contents. Directories are searched through in no particular order.  Its actions depend on whether the <strong>-d</strong> option is given, and on the <em>operation</em> parameter, which must be a comma-seperated list of <strong>scan</strong>, <strong>report</strong>, <strong>delete</strong>:</p><h3>Without \fB-d\fP</h3>
<p><strong>dupemap</strong> will take action when it sees the same checksum repeated more than once, i.e. it simply finds duplicates recursively.  The action depends on <em>operation</em>:</p>
<dl class='dl-vertical'>
  <dt>
    <strong>report</strong>
  </dt>
  <dd>
    <p>Report what files are encountered more than once, printing their names to standard output.</p>
  </dd>
  <dt>
    <strong>delete</strong>[<strong>,report</strong>]
  </dt>
  <dd>
    <p>Delete files that are encountered more than once.  Print their names if <strong>report</strong> is also given. <em>\s-1WARNING:\s0</em> use the <strong>report</strong> operation first to see what will be deleted. <em>\s-1WARNING:\s0</em> You are advised to make a backup of the target first, e.g. with \*(C`cp -al\*(C' (for \s-1GNU\s0 cp) to create hard links recursively.</p>
  </dd>

</dl>

<h3>With \fB-d\fP</h3>
<p>The <em>database</em> argument to <strong>-d</strong> will denote a database file (see the \*(L"\s-1DATABASE\s0\*(R" section in this manual for details) to read from or write to.  In this mode, the <strong>scan</strong> operation should be run on one <em>path</em>, followed by the <strong>report</strong> or <strong>delete</strong> operation on another (<em>not the same!</em>) <em>path</em>.</p>
<dl class='dl-vertical'>
  <dt>
    <strong>scan</strong>
  </dt>
  <dd>
    <p>Add the checksum of each file to <em>database</em>.  This operation must be run initially to create the database.  To start over, you must manually delete the database file(s) (see the \*(L"\s-1DATABASE\s0\*(R" section).</p>
  </dd>
  <dt>
    <strong>report</strong>
  </dt>
  <dd>
    <p>Print each file name if its checksum is found in <em>database</em>.</p>
  </dd>
  <dt>
    <strong>delete</strong>[<strong>,report</strong>]
  </dt>
  <dd>
    <p>Delete each file if its checksum is found in <em>database</em>.  If <strong>report</strong> is also present, print the name of each deleted file. <em>\s-1WARNING:\s0</em> if you run <strong>dupemap delete</strong> on the same <em>path</em> you just ran <strong>dupemap scan</strong> on, it will <em>delete every file!</em> The idea of these options is to scan one <em>path</em> and delete files in a second <em>path</em>. <em>\s-1WARNING:\s0</em> use the <strong>report</strong> operation first to see what will be deleted. <em>\s-1WARNING:\s0</em> You are advised to make a backup of the target first, e.g. with \*(C`cp -al\*(C' (for \s-1GNU\s0 cp) to create hard links recursively.</p>
  </dd>

</dl>


        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">OPTIONS</h2>
        <div class="sectioncontent">

<dl class='dl-vertical'>
  <dt>
    <strong>-d</strong> <em>database</em>
  </dt>
  <dd>
    <p>Use <em>database</em> as an on-disk database to read from or write to.  See the \*(L"\s-1DESCRIPTION\s0\*(R" section above about how this influences the operation of <strong>dupemap</strong>.</p>
  </dd>
  <dt>
    <strong>-I</strong> <em>file</em>
  </dt>
  <dd>
    <p>Reads input files from <em>file</em> in addition to those listed on the command line. If <em>file</em> is \*(C`-\*(C', read from standard input.  Each line will be interpreted as a file name. The paths given here will \s-1NOT\s0 be scanned recursively.  Directories will be ignored and symlinks will be followed.</p>
  </dd>
  <dt>
    <strong>-m</strong> <em>minsize</em>
  </dt>
  <dd>
    <p>Ignore files below this size.</p>
  </dd>
  <dt>
    <strong>-M</strong> <em>maxsize</em>
  </dt>
  <dd>
    <p>Ignore files above this size.</p>
  </dd>

</dl>

        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">USAGE</h2>
        <div class="sectioncontent">
<h3>General usage</h3>
<p>The easiest operations to understand is when the <strong>-d</strong> option is not given.  To delete all duplicate files in <em>/tmp/recovered-files</em>, do:</p>
<pre>
    $ dupemap delete /tmp/recovered-files
</pre>
<p>Often, <strong>dupemap scan</strong> is run to produce a checksum database of all files in a directory tree.  Then <strong>dupemap delete</strong> is run on another directory, possibly following <strong>dupemap report</strong>.  For example, to delete all files in <em>/tmp/recovered-files</em> that already exist in <em></em><strong>$HOME</strong><em></em>, do this:</p><p>    $ dupemap -d homedir.map scan $HOME     $ dupemap -d homedir.map delete,report /tmp/recovered-files</p>
<h3>Usage with magicrescue</h3>
<p>The main application for <strong>dupemap</strong> is to take some pain out of performing undelete operations with <a href="../man1/magicrescue.1.html"><strong>magicrescue</strong>(1)</a>.  The reason is that <strong>magicrescue</strong> will extract every single file of the specified type on the block device, so undeleting files requires you to find a few files out of hundreds, which can take a long time if done manually.  What we want to do is to only extract the documents that don't exist on the file system already.</p><p>In the following scenario, you have accidentally deleted some important Word documents in Windows.  If this were a real-world scenario, then by all means use The Sleuth Kit.  However, <strong>magicrescue</strong> will work even when the directory entries were overwritten, i.e. more files were stored in the same folder later.</p><p>You boot into Linux and change to a directory with lots of space.  Mount the Windows partition, preferably read-only (especially with \s-1NTFS\s0), and create the directories we will use.</p><p>    $ mount -o ro /dev/hda1 /mnt/windows     $ mkdir healthy_docs rescued_docs</p><p>Extract all the healthy Word documents with <strong>magicrescue</strong> and build a database of their checksums.  It may seem a little redundant to send all the documents through <strong>magicrescue</strong> first, but the reason is that this process may modify them (e.g. stripping trailing garbage), and therefore their checksum will not be the same as the original documents.  Also, it will find documents embedded inside other files, such as uncompressed zip archives or files with the wrong extension.</p><p>    $ find /mnt/windows -type f &#92;       |magicrescue -I- -r msoffice -d healthy_docs     $ dupemap -d healthy_docs.map scan healthy_docs     $ rm -rf healthy_docs</p><p>Now rescue all \*(C`msoffice\*(C' documents from the block device and get rid of everything that's not a *.doc.</p><p>    $ magicrescue -Mo -r msoffice -d rescued_docs /dev/hda1 &#92;       |grep -v &apos;&#92;.doc$&apos;|xargs rm -f</p><p>Remove all the rescued documents that also appear on the file system, and remove duplicates.</p><p>    $ dupemap -d healthy_docs.map delete,report rescued_docs     $ dupemap delete,report rescued_docs</p><p>The <em>rescued_docs</em> folder should now contain only a few files.  This will be the undeleted files and some documents that were not stored in contiguous blocks (use that defragger ;-)).</p>
<h3>Usage with fsck</h3>
<p>In this scenario (based on a true story), you have a hard disk that's gone bad. You have managed to <em>dd</em> about 80% of the contents into the file <em>diskimage</em>, and you have an old backup from a few months ago.  The disk is using reiserfs on Linux.</p><p>First, use fsck to make the file system usable again.  It will find many nameless files and put them in <em>lost+found</em>.  You need to make sure there is some free space on the disk image, so fsck has something to work with.</p><p>    $ cp diskimage diskimage.bak     $ dd if=/dev/zero bs=1M count=2048 &gt;&gt; diskimage     $ reiserfsck --rebuild-tree diskimage     $ mount -o loop diskimage /mnt     $ ls /mnt/lost+found     (tons of files)</p><p>Our strategy will be to restore the system with the old backup as a base and merge the two other sets of files (<em>/mnt/lost+found</em> and <em>/mnt</em>) into the backup after eliminating duplicates.  Therefore we create a checksum database of the directory we have unpacked the backup in.</p><p>    $ dupemap -d backup.map scan ~/backup</p><p>Next, we eliminate all the files from the rescued image that are also present in the backup.</p><p>    $ dupemap -d backup.map delete,report /mnt</p><p>We also want to remove duplicates from <em>lost+found</em>, and we want to get rid of any files that are also present in the other directories in <em>/mnt</em>.</p><p>    $ dupemap delete,report /mnt/lost+found     $ ls /mnt|grep -v lost+found|xargs dupemap -d mnt.map scan     $ dupemap -d mnt.map delete,report /mnt/lost+found</p><p>This should leave only the files in <em>/mnt</em> that have changed since the last backup or got corrupted.  Particularly, the contents of <em>/mnt/lost+found</em> should now be reduced enough to manually sort through them (or perhaps use <a href="../man1/magicsort.1.html"><strong>magicsort</strong>(1)</a>).</p>
<h3>Primitive intrusion detection</h3>
<p>You can use <strong>dupemap</strong> to see what files change on your system.  This is one of the more exotic uses, and it's only included for inspiration.</p><p>First, you map the whole file system.</p><p>    $ dupemap -d old.map scan /</p><p>Then you come back a few days/weeks later and run <strong>dupemap report</strong>.  This will give you a view of what <em>has not</em> changed.  To see what <em>has</em> changed, you need a list of the whole file system.  You can get this list along with preparing a new map easily.  Both lists need to be sorted to be compared.</p><p>    $ dupemap -d old.map report /|sort &gt; unchanged_files     $ dupemap -d current.map scan /|sort &gt; current_files</p><p>All that's left to do is comparing these files and preparing for next week. This assumes that the dbm appends the \*(C`.db\*(C' extension to database files.</p><p>    $ diff unchanged_files current_files &gt; changed_files     $ mv current.map.db old.map.db</p>

        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">DATABASE</h2>
        <div class="sectioncontent">
<p>The actual database file(s) written by <strong>dupecheck</strong> will have some relation to the <em>database</em> argument, but most implementations append an extension.  For example, Berkeley \s-1DB\s0 names the files <em>database</em><strong>.db</strong>, while Solaris and \s-1GDBM\s0 creates both a <em>database</em><strong>.dir</strong> and <em>database</em><strong>.pag</strong> file.</p><p><strong>dupecheck</strong> depends on a database library for storing the checksums.  It currently requires the POSIX-standardized <strong>ndbm</strong> library, which must be present on XSI-compliant UNIXes.  Implementations are not required to handle hash key collisions, and a faliure to do that could make <strong>dupecheck</strong> delete too many files.  I haven't heard of such an implementation, though.</p><p>The current checksum algorithm is the file's \s-1CRC32\s0 combined with its size. Both values are stored in native byte order, and because of varying type sizes the database is <em>not</em> portable across architectures, compilers and operating systems.</p>
        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">RELATED TO dupemap&hellip;</h2>
        <div class="sectioncontent">
<p><a href="../man1/magicrescue.1.html"><strong>magicrescue</strong>(1)</a>, <strong>weeder</strong>(1)</p><p>This tool does the same thing <strong>weeder</strong> does, except that <strong>weeder</strong> cannot seem to handle many files without crashing, and it has no largefile support.</p>
        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">BUGS</h2>
        <div class="sectioncontent">
<p>There is a tiny chance that two different files can have the same checksum and size.  The probability of this happening is around 1 to 10^14, and since <strong>dupemap</strong> is part of the Magic Rescue package, which deals with disaster recovery, that chance becomes an insignificant part of the game.  You should consider this if you apply <strong>dupemap</strong> to other applications, especially if they are security-related (see next paragraph).</p><p>It is possible to craft a file to have a known \s-1CRC32\s0.  You need to keep this in mind if you use <strong>dupemap</strong> on untrusted data.  A solution to this could be to implement an option for using \s-1MD5\s0 checksums instead.</p>
        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">AUTHOR</h2>
        <div class="sectioncontent">
<p>Jonas Jensen &lt;jbj@knef.dk&gt;</p>
        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">LATEST VERSION</h2>
        <div class="sectioncontent">
<p>This tool is part of Magic Rescue.  You can find the latest version at &lt;http://jbj.rapanden.dk/magicrescue/&gt;</p>
        </div>
      </section>
<nav>
  <ul class="pager">
   <li class="previous"><a href="dup2dds.1.html"><span aria-hidden="true">&larr;</span> dup2dds.1: Dup2dds converts duplimate (dup) format to dds</a></li>
   <li class="next"><a href="duplicity.1.html">duplicity.1: Encrypted incremental backup to local or remote storage. <span aria-hidden="true">&rarr;</span></a></li>
  </ul>
</nav>

  </div>
  <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
  <!-- Include all compiled plugins (below), or include individual files as needed -->
  <script src="/js/bootstrap.min.js"></script>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-60781387-1', 'auto');
    ga('send', 'pageview');

  </script>
</body>
</html>
