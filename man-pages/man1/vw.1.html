<!DOCTYPE html>
<html lang="en">
<head>
  <link href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700&effect=destruction%7Cshadow-multiple" rel="stylesheet" type="text/css">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>vw: Vowpal wabbit -- fast online learning tool</title>
  <link href="/css/bootstrap.min.css" rel="stylesheet">
  <link href="/css/manpage.css" rel="stylesheet">
  <link rel="apple-touch-icon" sizes="57x57" href="/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192" href="/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png">
  <link rel="manifest" href="/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
  <meta name="description" content="Vowpal wabbit -- fast online learning tool">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@CartaTech">
  <meta name="twitter:creator" content="@CartaTech">
  <meta name="twitter:title" content="vw (1) manual">
  <meta name="twitter:description" content="Vowpal wabbit -- fast online learning tool">
  <meta name="twitter:image" content="https://www.carta.tech/images/vowpal-wabbit-vw-1.png">
  <meta property="og:url" content="https://www.carta.tech/man-pages/man1/vw.1.html" />
  <meta property="og:type" content="website" />
  <meta property="og:title" content="vw (1) manual" />
  <meta property="og:description" content="Vowpal wabbit -- fast online learning tool" />
  <meta property="fb:app_id" content="1241677679199500" />
  <meta property="og:image" content="https://www.carta.tech/images/vowpal-wabbit-vw-1.png" />
  <meta property="og:image:width" content="600" />
  <meta property="og:image:height" content="315" />
</head>
<body>
  <div class="container final">
          <div class="page-header">
        <h1 class="font-effect-destruction">vw<small> (1)</small></h1>
        <p class="lead">Vowpal wabbit -- fast online learning tool</p>
      </div>

    <ol class="breadcrumb" itemscope itemtype="http://schema.org/BreadcrumbList">
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/">
      <span itemprop="name">Carta.tech</span>
    </a>
    <meta itemprop="position" content="1" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/">
      <span itemprop="name">Man Pages</span>
    </a>
    <meta itemprop="position" content="2" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/man1/">
      <span itemprop="name">Executable programs or shell commands</span>
    </a>
    <meta itemprop="position" content="3" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/man1/vw.1.html">
      <span itemprop="name">vw: Vowpal wabbit -- fast online learning tool</span>
    </a>
    <meta itemprop="position" content="4" />
  </li>
</ol>
<ol class="breadcrumb" itemscope itemtype="http://schema.org/BreadcrumbList">
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/">
      <span itemprop="name">Carta.tech</span>
    </a>
    <meta itemprop="position" content="1" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/packages/">
      <span itemprop="name">Packages</span>
    </a>
    <meta itemprop="position" content="2" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/packages/vowpal-wabbit/">
      <span itemprop="name">vowpal-wabbit</span>
    </a>
    <meta itemprop="position" content="3" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/man1/vw.1.html">
      <span itemprop="name">vw: Vowpal wabbit -- fast online learning tool</span>
    </a>
    <meta itemprop="position" content="4" />
  </li>
</ol>
    
      <section>
        <h2 class="font-effect-shadow-multiple">DESCRIPTION</h2>
        <div class="sectioncontent">
<h3>VW options:</h3>

<dl class='dl-vertical'>
  <dt>
    <p><strong>-h</strong> [ <strong>--help</strong> ]</p>
  </dt>
  <dd>
    <p>Look here: http://hunch.net/~vw/ and click on Tutorial.</p>
  </dd>
  <dt>
    <p><strong>--active_learning</strong></p>
  </dt>
  <dd>
    <p>active learning mode</p>
  </dd>
  <dt>
    <p><strong>--active_simulation</strong></p>
  </dt>
  <dd>
    <p>active learning simulation mode</p>
  </dd>
  <dt>
    <p><strong>--active_mellowness</strong> arg</p>
  </dt>
  <dd>
    <p>active learning mellowness parameter c_0. Default 8</p>
  </dd>
  <dt>
    <p><strong>--binary</strong></p>
  </dt>
  <dd>
    <p>report loss as binary classification on <strong>-1</strong>,1</p>
  </dd>
  <dt>
    <p><strong>--autolink</strong> arg</p>
  </dt>
  <dd>
    <p>create link function with polynomial d</p>
  </dd>
  <dt>
    <p><strong>--sgd</strong></p>
  </dt>
  <dd>
    <p>use regular stochastic gradient descent update.</p>
  </dd>
  <dt>
    <p><strong>--adaptive</strong></p>
  </dt>
  <dd>
    <p>use adaptive, individual learning rates.</p>
  </dd>
  <dt>
    <p><strong>--invariant</strong></p>
  </dt>
  <dd>
    <p>use safe/importance aware updates.</p>
  </dd>
  <dt>
    <p><strong>--normalized</strong></p>
  </dt>
  <dd>
    <p>use per feature normalized updates</p>
  </dd>
  <dt>
    <p><strong>--exact_adaptive_norm</strong></p>
  </dt>
  <dd>
    <p>use current default invariant normalized adaptive update rule</p>
  </dd>
  <dt>
    <p><strong>-a</strong> [ <strong>--audit</strong> ]</p>
  </dt>
  <dd>
    <p>print weights of features</p>
  </dd>
  <dt>
    <p><strong>-b</strong> [ <strong>--bit_precision</strong> ] arg</p>
  </dt>
  <dd>
    <p>number of bits in the feature table</p>
  </dd>
  <dt>
    <p><strong>--bfgs</strong></p>
  </dt>
  <dd>
    <p>use bfgs optimization</p>
  </dd>
  <dt>
    <p><strong>-c</strong> [ <strong>--cache</strong> ]</p>
  </dt>
  <dd>
    <p>Use a cache.  The default is &lt;data&gt;.cache</p>
  </dd>
  <dt>
    <p><strong>--cache_file</strong> arg</p>
  </dt>
  <dd>
    <p>The location(s) of cache_file.</p>
  </dd>
  <dt>
    <p><strong>--compressed</strong></p>
  </dt>
  <dd>
    <p>use gzip format whenever possible. If a cache file is being created, this option creates a compressed cache file. A mixture of raw-text & compressed inputs are supported with autodetection.</p>
  </dd>
  <dt>
    <p><strong>--no_stdin</strong></p>
  </dt>
  <dd>
    <p>do not default to reading from stdin</p>
  </dd>
  <dt>
    <p><strong>--conjugate_gradient</strong></p>
  </dt>
  <dd>
    <p>use conjugate gradient based optimization</p>
  </dd>
  <dt>
    <p><strong>--csoaa</strong> arg</p>
  </dt>
  <dd>
    <p>Use one-against-all multiclass learning with &lt;k&gt; costs</p>
  </dd>
  <dt>
    <p><strong>--wap</strong> arg</p>
  </dt>
  <dd>
    <p>Use weighted all-pairs multiclass learning with &lt;k&gt; costs</p>
  </dd>
  <dt>
    <p><strong>--csoaa_ldf</strong> arg</p>
  </dt>
  <dd>
    <p>Use one-against-all multiclass learning with label dependent features.  Specify singleline or multiline.</p>
  </dd>
  <dt>
    <p><strong>--wap_ldf</strong> arg</p>
  </dt>
  <dd>
    <p>Use weighted all-pairs multiclass learning with label dependent features.</p><ul>
<li><p>Specify singleline or multiline.</p></li>
</ul>
  </dd>
  <dt>
    <p><strong>--cb</strong> arg</p>
  </dt>
  <dd>
    <p>Use contextual bandit learning with &lt;k&gt; costs</p>
  </dd>
  <dt>
    <p><strong>--l1</strong> arg</p>
  </dt>
  <dd>
    <p>l_1 lambda</p>
  </dd>
  <dt>
    <p><strong>--l2</strong> arg</p>
  </dt>
  <dd>
    <p>l_2 lambda</p>
  </dd>
  <dt>
    <p><strong>-d</strong> [ <strong>--data</strong> ] arg</p>
  </dt>
  <dd>
    <p>Example Set</p>
  </dd>
  <dt>
    <p><strong>--daemon</strong></p>
  </dt>
  <dd>
    <p>persistent daemon mode on port 26542</p>
  </dd>
  <dt>
    <p><strong>--num_children</strong> arg</p>
  </dt>
  <dd>
    <p>number of children for persistent daemon mode</p>
  </dd>
  <dt>
    <p><strong>--pid_file</strong> arg</p>
  </dt>
  <dd>
    <p>Write pid file in persistent daemon mode</p>
  </dd>
  <dt>
    <p><strong>--decay_learning_rate</strong> arg</p>
  </dt>
  <dd>
    <p>Set Decay factor for learning_rate between passes</p>
  </dd>
  <dt>
    <p><strong>--input_feature_regularizer</strong> arg</p>
  </dt>
  <dd>
    <p>Per feature regularization input file</p>
  </dd>
  <dt>
    <p><strong>-f</strong> [ <strong>--final_regressor</strong> ] arg</p>
  </dt>
  <dd>
    <p>Final regressor</p>
  </dd>
  <dt>
    <p><strong>--readable_model</strong> arg</p>
  </dt>
  <dd>
    <p>Output human-readable final regressor</p>
  </dd>
  <dt>
    <p><strong>--hash</strong> arg</p>
  </dt>
  <dd>
    <p>how to hash the features. Available options: strings, all</p>
  </dd>
  <dt>
    <p><strong>--hessian_on</strong></p>
  </dt>
  <dd>
    <p>use second derivative in line search</p>
  </dd>
  <dt>
    <p><strong>--version</strong></p>
  </dt>
  <dd>
    <p>Version information</p>
  </dd>
  <dt>
    <p><strong>--ignore</strong> arg</p>
  </dt>
  <dd>
    <p>ignore namespaces beginning with character &lt;arg&gt;</p>
  </dd>
  <dt>
    <p><strong>--keep</strong> arg</p>
  </dt>
  <dd>
    <p>keep namespaces beginning with character &lt;arg&gt;</p>
  </dd>
  <dt>
    <p><strong>-k</strong> [ <strong>--kill_cache</strong> ]</p>
  </dt>
  <dd>
    <p>do not reuse existing cache: create a new one always</p>
  </dd>
  <dt>
    <p><strong>--initial_weight</strong> arg</p>
  </dt>
  <dd>
    <p>Set all weights to an initial value of 1.</p>
  </dd>
  <dt>
    <p><strong>-i</strong> [ <strong>--initial_regressor</strong> ] arg</p>
  </dt>
  <dd>
    <p>Initial regressor(s)</p>
  </dd>
  <dt>
    <p><strong>--initial_pass_length</strong> arg</p>
  </dt>
  <dd>
    <p>initial number of examples per pass</p>
  </dd>
  <dt>
    <p><strong>--initial_t</strong> arg</p>
  </dt>
  <dd>
    <p>initial t value</p>
  </dd>
  <dt>
    <p><strong>--lda</strong> arg</p>
  </dt>
  <dd>
    <p>Run lda with &lt;int&gt; topics</p>
  </dd>
  <dt>
    <p><strong>--span_server</strong> arg</p>
  </dt>
  <dd>
    <p>Location of server for setting up spanning tree</p>
  </dd>
  <dt>
    <p><strong>--min_prediction</strong> arg</p>
  </dt>
  <dd>
    <p>Smallest prediction to output</p>
  </dd>
  <dt>
    <p><strong>--max_prediction</strong> arg</p>
  </dt>
  <dd>
    <p>Largest prediction to output</p>
  </dd>
  <dt>
    <p><strong>--mem</strong> arg</p>
  </dt>
  <dd>
    <p>memory in bfgs</p>
  </dd>
  <dt>
    <p><strong>--nn</strong> arg</p>
  </dt>
  <dd>
    <p>Use sigmoidal feedforward network with &lt;k&gt; hidden units</p>
  </dd>
  <dt>
    <p><strong>--noconstant</strong></p>
  </dt>
  <dd>
    <p>Don't add a constant feature</p>
  </dd>
  <dt>
    <p><strong>--noop</strong></p>
  </dt>
  <dd>
    <p>do no learning</p>
  </dd>
  <dt>
    <p><strong>--oaa</strong> arg</p>
  </dt>
  <dd>
    <p>Use one-against-all multiclass learning with &lt;k&gt; labels</p>
  </dd>
  <dt>
    <p><strong>--ect</strong> arg</p>
  </dt>
  <dd>
    <p>Use error correcting tournament with &lt;k&gt; labels</p>
  </dd>
  <dt>
    <p><strong>--output_feature_regularizer_binary</strong> arg</p>
  </dt>
  <dd>
    <p>Per feature regularization output file</p>
  </dd>
  <dt>
    <p><strong>--output_feature_regularizer_text</strong> arg Per feature regularization output file,</p>
  </dt>
  <dd>
    <p>in text</p>
  </dd>
  <dt>
    <p><strong>--port</strong> arg</p>
  </dt>
  <dd>
    <p>port to listen on</p>
  </dd>
  <dt>
    <p><strong>--power_t</strong> arg</p>
  </dt>
  <dd>
    <p>t power value</p>
  </dd>
  <dt>
    <p><strong>-l</strong> [ <strong>--learning_rate</strong> ] arg</p>
  </dt>
  <dd>
    <p>Set Learning Rate</p>
  </dd>
  <dt>
    <p><strong>--passes</strong> arg</p>
  </dt>
  <dd>
    <p>Number of Training Passes</p>
  </dd>
  <dt>
    <p><strong>--termination</strong> arg</p>
  </dt>
  <dd>
    <p>Termination threshold</p>
  </dd>
  <dt>
    <p><strong>-p</strong> [ <strong>--predictions</strong> ] arg</p>
  </dt>
  <dd>
    <p>File to output predictions to</p>
  </dd>
  <dt>
    <p><strong>-q</strong> [ <strong>--quadratic</strong> ] arg</p>
  </dt>
  <dd>
    <p>Create and use quadratic features</p>
  </dd>
  <dt>
    <p><strong>--cubic</strong> arg</p>
  </dt>
  <dd>
    <p>Create and use cubic features</p>
  </dd>
  <dt>
    <p><strong>--quiet</strong></p>
  </dt>
  <dd>
    <p>Don't output diagnostics</p>
  </dd>
  <dt>
    <p><strong>--rank</strong> arg</p>
  </dt>
  <dd>
    <p>rank for matrix factorization.</p>
  </dd>
  <dt>
    <p><strong>--random_weights</strong> arg</p>
  </dt>
  <dd>
    <p>make initial weights random</p>
  </dd>
  <dt>
    <p><strong>--random_seed</strong> arg</p>
  </dt>
  <dd>
    <p>seed random number generator</p>
  </dd>
  <dt>
    <p><strong>-r</strong> [ <strong>--raw_predictions</strong> ] arg</p>
  </dt>
  <dd>
    <p>File to output unnormalized predictions to</p>
  </dd>
  <dt>
    <p><strong>--ring_size</strong> arg</p>
  </dt>
  <dd>
    <p>size of example ring</p>
  </dd>
  <dt>
    <p><strong>--examples</strong> arg</p>
  </dt>
  <dd>
    <p>number of examples to parse</p>
  </dd>
  <dt>
    <p><strong>--save_per_pass</strong></p>
  </dt>
  <dd>
    <p>Save the model after every pass over data</p>
  </dd>
  <dt>
    <p><strong>--save_resume</strong></p>
  </dt>
  <dd>
    <p>save extra state so learning can be resumed later with new data</p>
  </dd>
  <dt>
    <p><strong>--sendto</strong> arg</p>
  </dt>
  <dd>
    <p>send examples to &lt;host&gt;</p>
  </dd>
  <dt>
    <p><strong>--searn</strong> arg</p>
  </dt>
  <dd>
    <p>use searn, argument=maximum action id</p>
  </dd>
  <dt>
    <p><strong>--searnimp</strong> arg</p>
  </dt>
  <dd>
    <p>use searn, argument=maximum action id or 0 for LDF</p>
  </dd>
  <dt>
    <p><strong>-t</strong> [ <strong>--testonly</strong> ]</p>
  </dt>
  <dd>
    <p>Ignore label information and just test</p>
  </dd>
  <dt>
    <p><strong>--loss_function</strong> arg (=squared)</p>
  </dt>
  <dd>
    <p>Specify the loss function to be used, uses squared by default. Currently available ones are squared, classic, hinge, logistic and quantile.</p>
  </dd>
  <dt>
    <p><strong>--quantile_tau</strong> arg (=0.5)</p>
  </dt>
  <dd>
    <p>Parameter &#92;tau associated with Quantile loss. Defaults to 0.5</p>
  </dd>
  <dt>
    <p><strong>--unique_id</strong> arg</p>
  </dt>
  <dd>
    <p>unique id used for cluster parallel jobs</p>
  </dd>
  <dt>
    <p><strong>--total</strong> arg</p>
  </dt>
  <dd>
    <p>total number of nodes used in cluster parallel job</p>
  </dd>
  <dt>
    <p><strong>--node</strong> arg</p>
  </dt>
  <dd>
    <p>node number in cluster parallel job</p>
  </dd>
  <dt>
    <p><strong>--sort_features</strong></p>
  </dt>
  <dd>
    <p>turn this on to disregard order in which features have been defined. This will lead to smaller cache sizes</p>
  </dd>
  <dt>
    <p><strong>--ngram</strong> arg</p>
  </dt>
  <dd>
    <p>Generate N grams</p>
  </dd>
  <dt>
    <p><strong>--skips</strong> arg</p>
  </dt>
  <dd>
    <p>Generate skips in N grams. This in conjunction with the ngram tag can be used to generate generalized n-skip-k-gram.</p>
  </dd>

</dl>


        </div>
      </section>
<nav>
  <ul class="pager">
   <li class="previous"><a href="vvp.1.html"><span aria-hidden="true">&larr;</span> vvp.1: Icarus verilog vvp runtime engine</a></li>
   <li class="next"><a href="vwebp.1.html">vwebp.1: Decompress a webp file and display it in a window <span aria-hidden="true">&rarr;</span></a></li>
  </ul>
</nav>

  </div>
  <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
  <!-- Include all compiled plugins (below), or include individual files as needed -->
  <script src="/js/bootstrap.min.js"></script>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-60781387-1', 'auto');
    ga('send', 'pageview');

  </script>
</body>
</html>
