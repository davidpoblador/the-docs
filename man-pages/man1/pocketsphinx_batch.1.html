<!DOCTYPE html>
<html lang="en">
<head>
  <link href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700&effect=destruction%7Cshadow-multiple" rel="stylesheet" type="text/css">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>pocketsphinx_batch: Run speech recognition in batch mode</title>
  <link href="/css/bootstrap.min.css" rel="stylesheet">
  <link href="/css/manpage.css" rel="stylesheet">
  <link rel="apple-touch-icon" sizes="57x57" href="/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192" href="/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png">
  <link rel="manifest" href="/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
  <meta name="description" content="Run speech recognition in batch mode">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@CartaTech">
  <meta name="twitter:creator" content="@CartaTech">
  <meta name="twitter:title" content="pocketsphinx_batch (1) manual">
  <meta name="twitter:description" content="Run speech recognition in batch mode">
  <meta name="twitter:image" content="https://www.carta.tech/images/pocketsphinx-pocketsphinx_batch-1.png">
  <meta property="og:url" content="https://www.carta.tech/man-pages/man1/pocketsphinx_batch.1.html" />
  <meta property="og:type" content="website" />
  <meta property="og:title" content="pocketsphinx_batch (1) manual" />
  <meta property="og:description" content="Run speech recognition in batch mode" />
  <meta property="fb:app_id" content="1241677679199500" />
  <meta property="og:image" content="https://www.carta.tech/images/pocketsphinx-pocketsphinx_batch-1.png" />
  <meta property="og:image:width" content="600" />
  <meta property="og:image:height" content="315" />
</head>
<body>
  <div class="container final">
          <div class="page-header">
        <h1 class="font-effect-destruction">pocketsphinx_batch<small> (1)</small></h1>
        <p class="lead">Run speech recognition in batch mode</p>
      </div>

    <ol class="breadcrumb" itemscope itemtype="http://schema.org/BreadcrumbList">
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/">
      <span itemprop="name">Carta.tech</span>
    </a>
    <meta itemprop="position" content="1" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/">
      <span itemprop="name">Man Pages</span>
    </a>
    <meta itemprop="position" content="2" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/man1/">
      <span itemprop="name">Executable programs or shell commands</span>
    </a>
    <meta itemprop="position" content="3" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/man1/pocketsphinx_batch.1.html">
      <span itemprop="name">pocketsphinx_batch: Run speech recognition in batch mode</span>
    </a>
    <meta itemprop="position" content="4" />
  </li>
</ol>
<ol class="breadcrumb" itemscope itemtype="http://schema.org/BreadcrumbList">
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/">
      <span itemprop="name">Carta.tech</span>
    </a>
    <meta itemprop="position" content="1" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/packages/">
      <span itemprop="name">Packages</span>
    </a>
    <meta itemprop="position" content="2" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/packages/pocketsphinx/">
      <span itemprop="name">pocketsphinx</span>
    </a>
    <meta itemprop="position" content="3" />
  </li>
  <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
    <a itemscope itemtype="http://schema.org/Thing" itemprop="item" href="/man-pages/man1/pocketsphinx_batch.1.html">
      <span itemprop="name">pocketsphinx_batch: Run speech recognition in batch mode</span>
    </a>
    <meta itemprop="position" content="4" />
  </li>
</ol>
    
      <section>
        <h2 class="font-effect-shadow-multiple">SYNOPSIS</h2>
        <div class="sectioncontent">
<p><strong>pocketsphinx_batch</strong> <strong>-hmm</strong> <em>hmmdir</em> <strong>-dict</strong> <em>dictfile</em> [<em> options </em>]...</p>
        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">DESCRIPTION</h2>
        <div class="sectioncontent">
<p>Run speech recognition over a list of utterances in batchmode.  A list of arguments follows:</p>
<dl class='dl-vertical'>
  <dt>
    <p><strong>-adcdev</strong></p>
  </dt>
  <dd>
    <p>name for audio input (platform-specific)</p>
  </dd>
  <dt>
    <p><strong>-adchdr</strong></p>
  </dt>
  <dd>
    <p>Size of audio file header in bytes (headers are ignored)</p>
  </dd>
  <dt>
    <p><strong>-adcin</strong></p>
  </dt>
  <dd>
    <p>Input is raw audio data</p>
  </dd>
  <dt>
    <p><strong>-agc</strong></p>
  </dt>
  <dd>
    <p>Automatic gain control for c0 ('max', 'emax', 'noise', or 'none')</p>
  </dd>
  <dt>
    <p><strong>-agcthresh</strong></p>
  </dt>
  <dd>
    <p>Initial threshold for automatic gain control</p>
  </dd>
  <dt>
    <p><strong>-allphone</strong></p>
  </dt>
  <dd>
    <p>Do phoneme recognition</p>
  </dd>
  <dt>
    <p><strong>-alpha</strong></p>
  </dt>
  <dd>
    <p>Preemphasis parameter</p>
  </dd>
  <dt>
    <p><strong>-backtrace</strong></p>
  </dt>
  <dd>
    <p>Print back trace of recognition results</p>
  </dd>
  <dt>
    <p><strong>-beam</strong></p>
  </dt>
  <dd>
    <p>Beam width applied to every frame in Viterbi search (smaller values mean wider beam)</p>
  </dd>
  <dt>
    <p><strong>-bestpath</strong></p>
  </dt>
  <dd>
    <p>Run bestpath (Dijkstra) search over word lattice (3rd pass)</p>
  </dd>
  <dt>
    <p><strong>-bestpathlw</strong></p>
  </dt>
  <dd>
    <p>Language model probability weight for bestpath search</p>
  </dd>
  <dt>
    <p><strong>-cachesen</strong></p>
  </dt>
  <dd>
    <p>Cache senone scores from first pass search</p>
  </dd>
  <dt>
    <p><strong>-cep2spec</strong></p>
  </dt>
  <dd>
    <p>Input is cepstral files, output is log spectral files</p>
  </dd>
  <dt>
    <p><strong>-cepdir</strong></p>
  </dt>
  <dd>
    <p>files directory (prefixed to filespecs in control file)</p>
  </dd>
  <dt>
    <p><strong>-cepext</strong></p>
  </dt>
  <dd>
    <p>Input files extension (prefixed to filespecs in control file)</p>
  </dd>
  <dt>
    <p><strong>-ceplen</strong></p>
  </dt>
  <dd>
    <p>Number of components in the input feature vector</p>
  </dd>
  <dt>
    <p><strong>-cmn</strong></p>
  </dt>
  <dd>
    <p>Cepstral mean normalization scheme ('current', 'prior', or 'none')</p>
  </dd>
  <dt>
    <p><strong>-cmninit</strong></p>
  </dt>
  <dd>
    <p>Initial values (comma-separated) for cepstral mean when 'prior' is used</p>
  </dd>
  <dt>
    <p><strong>-compallsen</strong></p>
  </dt>
  <dd>
    <p>Compute all senone scores in every frame (can be faster when there are many senones)</p>
  </dd>
  <dt>
    <p><strong>-ctl</strong></p>
  </dt>
  <dd>
    <p>file listing utterances to be processed</p>
  </dd>
  <dt>
    <p><strong>-ctlcount</strong></p>
  </dt>
  <dd>
    <p>No. of utterances to be processed (after skipping <strong>-ctloffset</strong> entries)</p>
  </dd>
  <dt>
    <p><strong>-ctlincr</strong></p>
  </dt>
  <dd>
    <p>Do every Nth line in the control file</p>
  </dd>
  <dt>
    <p><strong>-ctloffset</strong></p>
  </dt>
  <dd>
    <p>No. of utterances at the beginning of <strong>-ctl</strong> file to be skipped</p>
  </dd>
  <dt>
    <p><strong>-dict</strong></p>
  </dt>
  <dd>
    <p>pronunciation dictionary (lexicon) input file</p>
  </dd>
  <dt>
    <p><strong>-dither</strong></p>
  </dt>
  <dd>
    <p>Add 1/2-bit noise</p>
  </dd>
  <dt>
    <p><strong>-doublebw</strong></p>
  </dt>
  <dd>
    <p>Use double bandwidth filters (same center freq)</p>
  </dd>
  <dt>
    <p><strong>-dsratio</strong></p>
  </dt>
  <dd>
    <p>Frame GMM computation downsampling ratio</p>
  </dd>
  <dt>
    <p><strong>-fbtype</strong></p>
  </dt>
  <dd>
    <p>FB Type of mel_scale or log_linear</p>
  </dd>
  <dt>
    <p><strong>-fdict</strong></p>
  </dt>
  <dd>
    <p>word pronunciation dictionary input file</p>
  </dd>
  <dt>
    <p><strong>-feat</strong></p>
  </dt>
  <dd>
    <p>Feature stream type, depends on the acoustic model</p>
  </dd>
  <dt>
    <p><strong>-fillpen</strong></p>
  </dt>
  <dd>
    <p>Filler word transition penalty</p>
  </dd>
  <dt>
    <p><strong>-frate</strong></p>
  </dt>
  <dd>
    <p>Frame rate</p>
  </dd>
  <dt>
    <p><strong>-fsg</strong></p>
  </dt>
  <dd>
    <p>state grammar</p>
  </dd>
  <dt>
    <p><strong>-fsgbfs</strong></p>
  </dt>
  <dd>
    <p>Force backtrace from FSG final state</p>
  </dd>
  <dt>
    <p><strong>-fsgctlfn</strong></p>
  </dt>
  <dd>
    <p>finite state grammar control file</p>
  </dd>
  <dt>
    <p><strong>-fsgusealtpron</strong></p>
  </dt>
  <dd>
    <p>Use alternative pronunciations for FSG</p>
  </dd>
  <dt>
    <p><strong>-fsgusefiller</strong></p>
  </dt>
  <dd>
    <p>(FSG Mode (Mode 2) only) Insert filler words at each state.</p>
  </dd>
  <dt>
    <p><strong>-fwd3g</strong></p>
  </dt>
  <dd>
    <p>Use trigrams in first pass search</p>
  </dd>
  <dt>
    <p><strong>-fwdflat</strong></p>
  </dt>
  <dd>
    <p>Run forward flat-lexicon search over word lattice (2nd pass)</p>
  </dd>
  <dt>
    <p><strong>-fwdflatbeam</strong></p>
  </dt>
  <dd>
    <p>Beam width applied to every frame in second-pass flat search</p>
  </dd>
  <dt>
    <p><strong>-fwdflatefwid</strong></p>
  </dt>
  <dd>
    <p>Minimum number of end frames for a word to be searched in fwdflat search</p>
  </dd>
  <dt>
    <p><strong>-fwdflatlw</strong></p>
  </dt>
  <dd>
    <p>Language model probability weight for flat lexicon (2nd pass) decoding</p>
  </dd>
  <dt>
    <p><strong>-fwdflatsfwin</strong></p>
  </dt>
  <dd>
    <p>Window of frames in lattice to search for successor words in fwdflat search</p>
  </dd>
  <dt>
    <p><strong>-fwdflatwbeam</strong></p>
  </dt>
  <dd>
    <p>Beam width applied to word exits in second-pass flat search</p>
  </dd>
  <dt>
    <p><strong>-fwdtree</strong></p>
  </dt>
  <dd>
    <p>Run forward lexicon-tree search (1st pass)</p>
  </dd>
  <dt>
    <p><strong>-hmm</strong></p>
  </dt>
  <dd>
    <p>containing acoustic model files.</p>
  </dd>
  <dt>
    <p><strong>-hyp</strong></p>
  </dt>
  <dd>
    <p>output file name</p>
  </dd>
  <dt>
    <p><strong>-hypseg</strong></p>
  </dt>
  <dd>
    <p>output with segmentation file name</p>
  </dd>
  <dt>
    <p><strong>-input_endian</strong></p>
  </dt>
  <dd>
    <p>Endianness of input data, big or little, ignored if NIST or MS Wav</p>
  </dd>
  <dt>
    <p><strong>-kdmaxbbi</strong></p>
  </dt>
  <dd>
    <p>Maximum number of Gaussians per leaf node in kd-Trees</p>
  </dd>
  <dt>
    <p><strong>-kdmaxdepth</strong></p>
  </dt>
  <dd>
    <p>Maximum depth of kd-Trees to use</p>
  </dd>
  <dt>
    <p><strong>-kdtree</strong></p>
  </dt>
  <dd>
    <p>file for Gaussian selection</p>
  </dd>
  <dt>
    <p><strong>-latsize</strong></p>
  </dt>
  <dd>
    <p>Lattice size</p>
  </dd>
  <dt>
    <p><strong>-lifter</strong></p>
  </dt>
  <dd>
    <p>Length of sin-curve for liftering, or 0 for no liftering.</p>
  </dd>
  <dt>
    <p><strong>-live</strong></p>
  </dt>
  <dd>
    <p>Get input from audio hardware</p>
  </dd>
  <dt>
    <p><strong>-lm</strong></p>
  </dt>
  <dd>
    <p>trigram language model input file</p>
  </dd>
  <dt>
    <p><strong>-lmctl</strong></p>
  </dt>
  <dd>
    <p>a set of language model</p>
  </dd>

</dl>
<p>The <strong>-hmm</strong> and <strong>-dict</strong> arguments are always required.  Either <strong>-lm</strong> or <strong>-fsg</strong> is required, depending on whether you are using a statistical language model or a finite-state grammar.  To do batchmode recognition, you will need to specify a control file, using <strong>-ctl</strong> This is a simple text file containing one entry per line.  Each entry is the name of an input file relative to the <strong>-cepdir</strong> directory, and without the filename extension (which is given in the <strong>-cepext</strong> argument).</p><p>If you are using acoustic feature files as input (see <strong>sphinx_fe</strong>(1) for information on how to generate these), you can also specify a subpart of a file, using the following format:</p><p><strong>FILENAME START-FRAME END-FRAME UTTERANCE-ID</strong></p>
        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">AUTHOR</h2>
        <div class="sectioncontent">
<p>Written by numerous people at CMU from 1994 onwards.  This manual page by David Huggins-Daines &lt;dhuggins@cs.cmu.edu&gt;</p>
        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">COPYRIGHT</h2>
        <div class="sectioncontent">
<p>Copyright &copy; 1994-2007 Carnegie Mellon University.  See the file <em>COPYING</em> included with this package for more information.</p>
        </div>
      </section>

      <section>
        <h2 class="font-effect-shadow-multiple">RELATED TO pocketsphinx_batch&hellip;</h2>
        <div class="sectioncontent">
<p><a href="../man1/pocketsphinx_continuous.1.html"><strong>pocketsphinx_continuous</strong>(1)</a>, <strong>sphinx_fe</strong>(1).</p>
        </div>
      </section>
<nav>
  <ul class="pager">
   <li class="previous"><a href="poc-http.1.html"><span aria-hidden="true">&larr;</span> poc-http.1: Send http mp3 streams</a></li>
   <li class="next"><a href="pocketsphinx_continuous.1.html">pocketsphinx_continuous.1: Run speech recognition in continuous listening mode <span aria-hidden="true">&rarr;</span></a></li>
  </ul>
</nav>

  </div>
  <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
  <!-- Include all compiled plugins (below), or include individual files as needed -->
  <script src="/js/bootstrap.min.js"></script>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-60781387-1', 'auto');
    ga('send', 'pageview');

  </script>
</body>
</html>
